# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å API —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
"""

import os
import time
import json
import hashlib
from datetime import datetime
from tqdm.auto import tqdm

try:
    import openai
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("‚ö†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ OpenAI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–µ —Å –ø–æ–º–æ—â—å—é pip install openai")

from cybersec_consultant.config import ConfigManager, RESPONSES_DIR, CACHE_DIR, get_api_key

class LLMInterface:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        self.config_manager = ConfigManager()
        self.client = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API –∫–ª—é—á–∞
        self.api_key = get_api_key()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é OpenAI API
        self.is_new_api = self._check_openai_version()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
        self._init_client()
        
        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫—ç—à–∞
        self.cache_dir = os.path.join(CACHE_DIR, "responses")
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫—ç—à –æ—Ç–≤–µ—Ç–æ–≤
        self.response_cache = self._load_response_cache()

    def _check_openai_version(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–µ—Ä—Å–∏—é OpenAI API"""
        if not OPENAI_AVAILABLE:
            return True  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–æ–≤—ã–π API –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        try:
            openai_version = openai.__version__
            is_new_api = int(openai_version.split('.')[0]) >= 1
            print(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤–µ—Ä—Å–∏—è OpenAI API: {openai_version}")
            print(f"   {'–ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å API (>=1.0.0)' if is_new_api else '–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å API (<1.0.0)'}")
            return is_new_api
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤–µ—Ä—Å–∏—é OpenAI API: {e}")
            return True  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–æ–≤—ã–π API –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    def _init_client(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç OpenAI"""
        if not OPENAI_AVAILABLE:
            print("‚ùå –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ OpenAI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
            return
        
        try:
            if self.is_new_api:
                self.client = OpenAI(api_key=self.api_key)
            else:
                openai.api_key = self.api_key
            print("‚úÖ –ö–ª–∏–µ–Ω—Ç OpenAI —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI: {str(e)}")
    
    def _load_response_cache(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—ç—à –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
        cache_file = os.path.join(self.cache_dir, "response_cache.json")
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cache = json.load(f)
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –∫—ç—à –æ—Ç–≤–µ—Ç–æ–≤ ({len(cache)} –∑–∞–ø–∏—Å–µ–π)")
                return cache
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫—ç—à–∞ –æ—Ç–≤–µ—Ç–æ–≤: {str(e)}")
        return {}
    
    def _save_response_cache(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—ç—à –æ—Ç–≤–µ—Ç–æ–≤ –≤ —Ñ–∞–π–ª"""
        cache_file = os.path.join(self.cache_dir, "response_cache.json")
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.response_cache, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫—ç—à–∞ –æ—Ç–≤–µ—Ç–æ–≤: {str(e)}")
            return False

    def generate_answer(self, system_prompt, user_prompt, 
                       model=None, temperature=0, use_cache=True):
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏

        Args:
            system_prompt (str): –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            user_prompt (str): –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            model (str): –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
            temperature (float): –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            use_cache (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à –∏–ª–∏ –Ω–µ—Ç

        Returns:
            dict: –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if not OPENAI_AVAILABLE or not self.client:
            return {
                "answer": "–û—à–∏–±–∫–∞: API OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É —Å –ø–æ–º–æ—â—å—é pip install openai",
                "success": False,
                "cached": False,
                "model": model,
                "tokens": 0,
                "execution_time": 0,
                "cost": 0
            }
        
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –±–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if model is None:
            model = self.config_manager.get_setting("models", "default", "gpt-4o-mini")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∫—ç—à–∞
        cache_key = hashlib.md5(f"{system_prompt}_{user_prompt}_{model}_{temperature}".encode()).hexdigest()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤ –∫—ç—à–µ
        if use_cache and cache_key in self.response_cache:
            cached_response = self.response_cache[cache_key]
            cached_response["cached"] = True
            return cached_response

        # –ï—Å–ª–∏ –Ω–µ—Ç –≤ –∫—ç—à–µ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        try:
            print(f"\nü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ API OpenAI (–º–æ–¥–µ–ª—å: {model})...")
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            with tqdm(total=100, desc="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞") as pbar:
                start_time = time.time()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞
                pbar.update(10)  # 10% - –Ω–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ API –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Ä—Å–∏–∏
                if self.is_new_api:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π API (>=1.0.0)
                    completion = self.client.chat.completions.create(
                        model=model,
                        messages=messages,
                        temperature=temperature
                    )
                    answer = completion.choices[0].message.content
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π API (<1.0.0)
                    completion = openai.ChatCompletion.create(
                        model=model,
                        messages=messages,
                        temperature=temperature
                    )
                    answer = completion.choices[0].message.content
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä (–∫–∞–∫ –±—É–¥—Ç–æ –∑–∞–ø—Ä–æ—Å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ)
                pbar.update(40)  # 50% - –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
                
                # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
                pbar.update(50)  # 100% - –ø–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞

            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            input_tokens = (len(system_prompt) + len(user_prompt)) // 3
            output_tokens = len(answer) // 3
            total_tokens = input_tokens + output_tokens

            # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å (–ø—Ä–∏–º–µ—Ä–Ω–æ)
            input_cost_per_1000 = 0.01
            output_cost_per_1000 = 0.03
            input_cost = (input_tokens / 1000) * input_cost_per_1000
            output_cost = (output_tokens / 1000) * output_cost_per_1000
            total_cost = input_cost + output_cost

            # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            execution_time = time.time() - start_time

            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                "answer": answer,
                "success": True,
                "cached": False,
                "model": model,
                "tokens": total_tokens,
                "execution_time": execution_time,
                "cost": total_cost,
                "timestamp": datetime.now().isoformat()
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self.response_cache[cache_key] = result
            self._save_response_cache()

            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            print(f"\n‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç API –∑–∞ {execution_time:.2f} —Å–µ–∫.")
            print(f"üìä –ú–æ–¥–µ–ª—å: {model}")
            print(f"üìù –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: {total_tokens} —Ç–æ–∫–µ–Ω–æ–≤ (–≤–≤–æ–¥: {input_tokens}, –≤—ã–≤–æ–¥: {output_tokens})")
            print(f"üí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞: ${total_cost:.6f}")

            return result

        except Exception as e:
            error_message = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏ {model}: {str(e)}"
            print(error_message)
            
            return {
                "answer": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}",
                "success": False,
                "cached": False,
                "model": model,
                "tokens": 0,
                "execution_time": time.time() - start_time if 'start_time' in locals() else 0,
                "cost": 0,
                "error": str(e)
            }

    def save_response_to_file(self, query, response_data, filename=None):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–≤–µ—Ç –≤ —Ñ–∞–π–ª

        Args:
            query (str): –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            response_data (dict): –î–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç–∞
            filename (str): –ò–º—è —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(RESPONSES_DIR, exist_ok=True)
        
        # –ï—Å–ª–∏ –∏–º—è —Ñ–∞–π–ª–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            query_part = "".join(x for x in query[:30] if x.isalnum() or x.isspace()).strip().replace(" ", "_")
            if not query_part:
                query_part = "response"
            filename = f"{timestamp}_{query_part}.md"
        
        filepath = os.path.join(RESPONSES_DIR, filename)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        answer = response_data.get("answer", "–û—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω")
        model = response_data.get("model", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å")
        tokens = response_data.get("tokens", 0)
        cost = response_data.get("cost", 0)
        cached = response_data.get("cached", False)
        execution_time = response_data.get("execution_time", 0)
        
        content = f"# –û—Ç–≤–µ—Ç –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞ –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏\n\n"
        content += f"**–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        content += f"## –í–æ–ø—Ä–æ—Å\n\n{query}\n\n"
        content += f"## –û—Ç–≤–µ—Ç\n\n{answer}\n\n"
        content += f"---\n\n"
        content += f"**–ú–æ–¥–µ–ª—å:** {model}\n\n"
        content += f"**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à:** {'–î–∞' if cached else '–ù–µ—Ç'}\n\n"
        if not cached:
            content += f"**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤:** {tokens}\n\n"
            content += f"**–ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å:** ${cost:.6f}\n\n"
        content += f"**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** {execution_time:.2f} —Å–µ–∫.\n"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"üíæ –û—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {filepath}")
            return filepath
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –≤ —Ñ–∞–π–ª: {str(e)}")
            return None
