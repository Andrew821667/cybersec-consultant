# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (BM25 + –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫)
"""

import os
import math
import pickle
import time
import re
import numpy as np
from collections import Counter

from cybersec_consultant.config import ConfigManager, INDICES_DIR
from cybersec_consultant.state_management import STATE
from cybersec_consultant.embeddings import VectorSearchManager
from cybersec_consultant.utils.text_processing import TextProcessor


class BM25:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ BM25"""

    def __init__(self, k1=1.5, b=0.75):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ BM25
        
        Args:
            k1 (float): –ü–∞—Ä–∞–º–µ—Ç—Ä –Ω–∞—Å—ã—â–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã —Ç–µ—Ä–º–∏–Ω–∞
            b (float): –ü–∞—Ä–∞–º–µ—Ç—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª–∏–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        self.k1 = k1
        self.b = b
        self.corpus = []
        self.doc_freqs = Counter()
        self.idf = {}
        self.doc_len = []
        self.avgdl = 0
        self.text_processor = TextProcessor()
        
    def _tokenize(self, text):
        """
        –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç
        
        Args:
            text (str): –¢–µ–∫—Å—Ç –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤
        """
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        text = self.text_processor.clean_text(text)
        # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º
        tokens = re.findall(r'\b\w+\b', text.lower())
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        tokens = [token for token in tokens if token not in self.text_processor.stopwords]
        return tokens
        
    def fit(self, documents):
        """
        –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å BM25 –Ω–∞ –∫–æ—Ä–ø—É—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        
        Args:
            documents (list): –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–æ–±—ä–µ–∫—Ç–æ–≤ Document)
        """
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        self.corpus = [doc.page_content for doc in documents]
        
        # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        tokenized_corpus = [self._tokenize(doc) for doc in self.corpus]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        self.doc_len = [len(tokens) for tokens in tokenized_corpus]
        self.avgdl = sum(self.doc_len) / len(self.doc_len) if self.doc_len else 0
        
        # –í—ã—á–∏—Å–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
        for tokens in tokenized_corpus:
            for token in set(tokens):
                self.doc_freqs[token] += 1
        
        # –í—ã—á–∏—Å–ª—è–µ–º IDF –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞
        self._compute_idf()
    
    def _compute_idf(self):
        """–í—ã—á–∏—Å–ª—è–µ—Ç IDF –¥–ª—è –≤—Å–µ—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ"""
        N = len(self.corpus)
        for term, n in self.doc_freqs.items():
            # BM25 IDF —Ñ–æ—Ä–º—É–ª–∞
            self.idf[term] = math.log((N - n + 0.5) / (n + 0.5) + 1)
    
    def search(self, query, top_k=10):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º BM25
        
        Args:
            query (str): –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–∏–Ω–¥–µ–∫—Å_–¥–æ–∫—É–º–µ–Ω—Ç–∞, –æ—Ü–µ–Ω–∫–∞)
        """
        # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
        query_tokens = self._tokenize(query)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ—Ü–µ–Ω–∫–∏ BM25 –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        scores = [self._score(query_tokens, i) for i in range(len(self.corpus))]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –æ—Ü–µ–Ω–∫–µ
        top_docs = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:top_k]
        
        return top_docs
    
    def _score(self, query_tokens, doc_idx):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É BM25 –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
        
        Args:
            query_tokens (list): –¢–æ–∫–µ–Ω—ã –∑–∞–ø—Ä–æ—Å–∞
            doc_idx (int): –ò–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞
            
        Returns:
            float: –û—Ü–µ–Ω–∫–∞ BM25
        """
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
        if not query_tokens:
            return 0
        
        # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        doc_tokens = self._tokenize(self.corpus[doc_idx])
        
        # –í—ã—á–∏—Å–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
        freq = Counter(doc_tokens)
        
        # –î–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc_len = self.doc_len[doc_idx]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ—Ü–µ–Ω–∫—É BM25
        score = 0.0
        for token in query_tokens:
            if token not in self.idf:
                continue
                
            # –ü–æ–ª—É—á–∞–µ–º IDF –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞
            idf = self.idf[token]
            
            # –ü–æ–ª—É—á–∞–µ–º —á–∞—Å—Ç–æ—Ç—É —Ç–µ—Ä–º–∏–Ω–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
            term_freq = freq[token]
            
            # BM25 —Ñ–æ—Ä–º—É–ª–∞
            numerator = idf * term_freq * (self.k1 + 1)
            denominator = term_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)
            score += numerator / denominator
        
        return score


class HybridSearchManager:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–∏—Å–∫–æ–º (BM25 + –≤–µ–∫—Ç–æ—Ä–Ω—ã–π)"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        self.config_manager = ConfigManager()
        self.vector_search = VectorSearchManager()
        self.bm25 = BM25()
        self.documents = []
        
        # –í–µ—Å –¥–ª—è —Å–º–µ—à–∏–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (0 = —Ç–æ–ª—å–∫–æ BM25, 1 = —Ç–æ–ª—å–∫–æ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫)
        STATE.hybrid_weight = self.config_manager.get_setting("settings", "hybrid_weight", 0.5)
    
    def create_indexes(self, documents, index_name="cybersec_index"):
        """
        –°–æ–∑–¥–∞–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å (–≤–µ–∫—Ç–æ—Ä–Ω—ã–π + BM25)
        
        Args:
            documents (list): –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            index_name (str): –ò–º—è –∏–Ω–¥–µ–∫—Å–∞
            
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏
        """
        if not documents:
            print("‚ùå –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç")
            return False
            
        print(f"üîÑ –°–æ–∑–¥–∞–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å –∏–∑ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        self.documents = documents
        
        try:
            start_time = time.time()
            
            # 1. –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å
            vector_db = self.vector_search.create_index(documents, index_name)
            if not vector_db:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å")
                return False
                
            # 2. –°–æ–∑–¥–∞–µ–º BM25 –∏–Ω–¥–µ–∫—Å
            print("üîÑ –°–æ–∑–¥–∞–µ–º BM25 –∏–Ω–¥–µ–∫—Å...")
            self.bm25.fit(documents)
            
            # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º BM25 –∏–Ω–¥–µ–∫—Å
            bm25_path = os.path.join(INDICES_DIR, index_name, "bm25.pkl")
            with open(bm25_path, 'wb') as f:
                pickle.dump(self.bm25, f)
            
            elapsed_time = time.time() - start_time
            print(f"‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å '{index_name}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥.")
            
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞: {str(e)}")
            return False
    
    def load_indexes(self, index_name="cybersec_index"):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        
        Args:
            index_name (str): –ò–º—è –∏–Ω–¥–µ–∫—Å–∞
            
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏
        """
        print(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å '{index_name}'...")
        
        try:
            start_time = time.time()
            
            # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å
            vector_db = self.vector_search.load_index(index_name)
            if not vector_db:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å")
                return False
            
            # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
            docs_path = os.path.join(INDICES_DIR, index_name, "documents.pkl")
            with open(docs_path, 'rb') as f:
                self.documents = pickle.load(f)
            
            # 3. –ó–∞–≥—Ä—É–∂–∞–µ–º BM25 –∏–Ω–¥–µ–∫—Å
            bm25_path = os.path.join(INDICES_DIR, index_name, "bm25.pkl")
            if os.path.exists(bm25_path):
                with open(bm25_path, 'rb') as f:
                    self.bm25 = pickle.load(f)
            else:
                # –ï—Å–ª–∏ BM25 –∏–Ω–¥–µ–∫—Å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ
                print("‚ö†Ô∏è BM25 –∏–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π...")
                self.bm25.fit(self.documents)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º BM25 –∏–Ω–¥–µ–∫—Å
                with open(bm25_path, 'wb') as f:
                    pickle.dump(self.bm25, f)
            
            elapsed_time = time.time() - start_time
            print(f"‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å '{index_name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥.")
            
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞: {str(e)}")
            return False
    
    def hybrid_search(self, query, k=3, use_cache=True, weight=None):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º BM25 –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        
        Args:
            query (str): –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            k (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            use_cache (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à
            weight (float): –í–µ—Å –¥–ª—è —Å–º–µ—à–∏–≤–∞–Ω–∏—è (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫)
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–¥–æ–∫—É–º–µ–Ω—Ç, –æ—Ü–µ–Ω–∫–∞)
        """
        if STATE.vector_db is None:
            print("‚ùå –í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–Ω–¥–µ–∫—Å—ã.")
            return []
            
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏–ª–∏ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        hybrid_weight = weight if weight is not None else STATE.hybrid_weight
        
        # –ò—â–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        cache_key = f"{query}_{k}_{hybrid_weight}"
        cached_results = STATE.get_search_from_cache(cache_key, k) if use_cache else None
        if cached_results:
            print(f"üîÑ –ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}' (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∑—è—Ç—ã –∏–∑ –∫—ç—à–∞)")
            return cached_results
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            print(f"üîç –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}' (–≤–µ—Å={hybrid_weight:.2f})")
            start_time = time.time()
            
            # 1. –í—ã–ø–æ–ª–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
            vector_results = STATE.vector_db.similarity_search_with_score(query, k=k*2)
            
            # 2. –í—ã–ø–æ–ª–Ω—è–µ–º BM25 –ø–æ–∏—Å–∫
            bm25_results = self.bm25.search(query, top_k=k*2)
            
            # 3. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —É—á–µ—Ç–æ–º –≤–µ—Å–∞
            combined_results = self._combine_results(vector_results, bm25_results, hybrid_weight, k)
            
            # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            execution_time = time.time() - start_time
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫—ç—à
            if combined_results and use_cache:
                STATE.add_search_to_cache(cache_key, k, combined_results)
            
            print(f"‚úÖ –ü–æ–∏—Å–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {execution_time:.2f} —Å–µ–∫.")
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(combined_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            return combined_results
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
            return []
    
    def _combine_results(self, vector_results, bm25_results, weight, k):
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏ BM25 –ø–æ–∏—Å–∫–∞
        
        Args:
            vector_results (list): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ [(–¥–æ–∫—É–º–µ–Ω—Ç, –æ—Ü–µ–Ω–∫–∞), ...]
            bm25_results (list): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã BM25 –ø–æ–∏—Å–∫–∞ [(–∏–Ω–¥–µ–∫—Å, –æ—Ü–µ–Ω–∫–∞), ...]
            weight (float): –í–µ—Å –¥–ª—è —Å–º–µ—à–∏–≤–∞–Ω–∏—è (0 = —Ç–æ–ª—å–∫–æ BM25, 1 = —Ç–æ–ª—å–∫–æ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π)
            k (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–¥–æ–∫—É–º–µ–Ω—Ç, –æ—Ü–µ–Ω–∫–∞)
        """
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
        combined_scores = {}
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ü–µ–Ω–∫–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–æ–±—Ä–∞—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞, –º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
        if vector_results:
            # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è (–±–ª–∏–∂–µ = –ª—É—á—à–µ)
            vector_scores = [(doc, 1.0 / (1.0 + score)) for doc, score in vector_results]
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ü–µ–Ω–∫–∏ (0-1)
            max_vector_score = max(score for _, score in vector_scores)
            norm_vector_scores = [(doc, score / max_vector_score) for doc, score in vector_scores]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –≤ –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å
            for doc, score in norm_vector_scores:
                doc_id = id(doc)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º id –æ–±—ä–µ–∫—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∫–∞–∫ –∫–ª—é—á
                if doc_id not in combined_scores:
                    combined_scores[doc_id] = {"doc": doc, "vector_score": 0, "bm25_score": 0}
                combined_scores[doc_id]["vector_score"] = score
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ü–µ–Ω–∫–∏ BM25
        if bm25_results:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ü–µ–Ω–∫–∏ (0-1)
            max_bm25_score = max(score for _, score in bm25_results) if bm25_results else 1.0
            if max_bm25_score > 0:  # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
                norm_bm25_scores = [(idx, score / max_bm25_score) for idx, score in bm25_results]
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –≤ –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å
                for idx, score in norm_bm25_scores:
                    doc = self.documents[idx]
                    doc_id = id(doc)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º id –æ–±—ä–µ–∫—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∫–∞–∫ –∫–ª—é—á
                    if doc_id not in combined_scores:
                        combined_scores[doc_id] = {"doc": doc, "vector_score": 0, "bm25_score": 0}
                    combined_scores[doc_id]["bm25_score"] = score
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è –≤–µ—Å –¥–ª—è —Å–º–µ—à–∏–≤–∞–Ω–∏—è
        for doc_id in combined_scores:
            vector_score = combined_scores[doc_id]["vector_score"]
            bm25_score = combined_scores[doc_id]["bm25_score"]
            
            # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –æ—Ü–µ–Ω–æ–∫
            final_score = weight * vector_score + (1 - weight) * bm25_score
            combined_scores[doc_id]["final_score"] = final_score
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ –∏ –≤—ã–±–∏—Ä–∞–µ–º top-k
        sorted_results = sorted(
            combined_scores.values(), 
            key=lambda x: x["final_score"], 
            reverse=True
        )[:k]
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ (–¥–æ–∫—É–º–µ–Ω—Ç, –æ—Ü–µ–Ω–∫–∞)
        return [(item["doc"], item["final_score"]) for item in sorted_results]
    
    def adjust_weight(self, weight):
        """
        –†–µ–≥—É–ª–∏—Ä—É–µ—Ç –≤–µ—Å —Å–º–µ—à–∏–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        Args:
            weight (float): –ù–æ–≤—ã–π –≤–µ—Å (0-1)
            
        Returns:
            float: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –≤–µ—Å
        """
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤–µ—Å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]
        weight = max(0.0, min(1.0, weight))
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–æ–≤—ã–π –≤–µ—Å
        STATE.hybrid_weight = weight
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
        self.config_manager.set_setting("settings", "hybrid_weight", weight)
        
        print(f"‚úÖ –í–µ—Å –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {weight:.2f}")
        print(f"   (0.0 = —Ç–æ–ª—å–∫–æ BM25, 1.0 = —Ç–æ–ª—å–∫–æ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫)")
        
        return weight
